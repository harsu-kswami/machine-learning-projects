# Positional Encoding Visualizer

An interactive educational tool for understanding transformer positional encodings through hands-on visualization and experimentation.

## üéØ Project Overview

This project helps you build intuitive understanding of positional encoding mechanisms in transformers by:
- Implementing transformer components from scratch in PyTorch
- Creating interactive visualizations of attention patterns
- Comparing different positional encoding methods (Absolute, Relative, RoPE)
- Exploring how sequence length affects encoding effectiveness

## üöÄ Features

### Core Transformer Components
- **Multi-Head Self-Attention**: Interactive attention weight matrices with real-time QKV computations
- **Feed-Forward Networks**: Step-by-step linear transformation visualizations
- **Embedding Layers**: Token-to-vector conversion with dimension exploration

### Positional Encoding Systems
- **Absolute Encoding**: Sinusoidal pattern visualization across sequence positions
- **Relative Encoding**: Distance-based attention modification with bias matrices
- **RoPE (Rotary Position Embedding)**: 2D rotation visualization in embedding space

### Interactive Learning Tools
- Dynamic sequence length adjustment (5-100 tokens)
- Real-time parameter manipulation (dimensions, heads, temperature)
- Side-by-side encoding comparisons
- 3D visualization of encoding patterns
- Performance benchmarking suite

## üìã Requirements

- Python 3.8+
- PyTorch 1.12+
- Streamlit 1.28+
- Plotly 5.0+
- NumPy, Matplotlib, Seaborn

## üõ†Ô∏è Installation

